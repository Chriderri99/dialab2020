{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressione non Lineare (parte 2)\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "- Importare i package necessari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Jupyter, configurare l'output di matplotlib integrato nel notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio: Predizione dei prezzi delle case\n",
    "\n",
    "- Riprendiamo dalla scorsa esercitazione il dataset relativo ai prezzi delle case\n",
    "- Forniamo tale dataset all'URL https://git.io/fjGjx già adattato per essere caricato con `read_csv` con le opzioni di default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.exists(\"housing.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(\"https://git.io/fjGjx\", \"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lista delle variabili\n",
    "\n",
    "- CRIM: tasso di criminalità pro capite per zona\n",
    "- ZN: proporzione terreno residenziale per lotti maggiori di 25.000 piedi quadrati (circa 2300 m2)\n",
    "- INDUS: proporzione di acri industriali non commerciali per città\n",
    "- CHAS: variabile fittizia Charles River, 1 se il tratto affianca il fiume, altrimenti 0\n",
    "- NOX: concentrazione di ossido d’azoto (parti per 10 milioni)\n",
    "- RM: numero medio di stanze per abitazione\n",
    "- AGE: proporzione delle unità abitate costruite prima del 1940\n",
    "- DIS: distanze pesate verso i cinque uffici di collocamento di Boston\n",
    "- RAD: indice di accessibilità rispetto alle grandi vie radiali di comunicazione\n",
    "- TAX: tasso di imposte sulla casa per 10.000 dollari\n",
    "- PTRATIO: rapporto allievi-docenti per città\n",
    "- B: 1000(Bk - 0.63)2, dove Bk è la proporzione di persone di origine afroamericana\n",
    "- LSTAT: percentuale di popolazione con basso reddito\n",
    "- **MEDV: valore mediano delle abitazioni di proprietà in migliaia di dollari**\n",
    "  - vogliamo stimare il valore di questa variabile in funzione delle altre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estraiamo dal frame\n",
    "  - la serie `y` con i valori della variabile `MEDV` da prevedere\n",
    "  - il frame `X` con i valori di tutte le altre variabili, utilizzabili per la predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing[\"MEDV\"]\n",
    "X = housing.drop(columns=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Divisione tra training e validation set\n",
    "\n",
    "- Dividiamo i dati caricati casualmente in\n",
    "  - un _training set_ per addestrare i modelli\n",
    "  - un _validation set_ disgiunto su cui verificare l'accuratezza del modello\n",
    "- Usiamo la funzione `train_test_split` di scikit-learn\n",
    "  - con `test_size` indichiamo quanti dati vanno nel validation set, i restanti andranno nel training set\n",
    "  - con `random_state` fissiamo un seed per la suddivisione casuale\n",
    "  - la funzione mescola i dati di `X` e `y` in modo congiunto, mantenendo la corrispondenza esistente tra le posizioni dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funzioni per la validazione\n",
    "\n",
    "- Riprendiamo dalla prima parte le funzioni per estrarre e stampare le misure di valutazione del modello (MSE, errore relativo, R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo MSE e R²\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# definisco funzione per errore relativo\n",
    "def relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# funzione per calcolare e stampare tutte e tre\n",
    "def print_eval(X, y, model):\n",
    "    preds = model.predict(X)\n",
    "    print(\"   Mean squared error: {:.5}\".format(mean_squared_error(y, preds)))\n",
    "    print(\"       Relative error: {:.5%}\".format(relative_error(y, preds)))\n",
    "    print(\"R-squared coefficient: {:.5}\".format(r2_score(y, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 1: Ripasso modelli\n",
    "\n",
    "Addestrare sul training set creato sopra tre modelli diversi con le seguenti configurazioni, per ciascuno stampare le misure di valutazione sul validation set e i coefficienti associati a ciascuna variabile\n",
    "\n",
    "- **(1a)** regressione lineare semplice\n",
    "- **(1b)** regressione lineare con regolarizzazione L2 (regressione ridge), assumendo $\\alpha=1$\n",
    "- **(1c)** regressione lineare con standardizzazione delle feature\n",
    "\n",
    "Infine:\n",
    "\n",
    "- **(1d)** visualizzare in un unico frame i coefficienti di tutti e tre i modelli (una riga per variabile, una colonna per modello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sono eseguiti quì tutti gli import necessari da scikit-learn\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 20.595\n",
      "       Relative error: 16.20789%\n",
      "R-squared coefficient: 0.72621\n"
     ]
    }
   ],
   "source": [
    "model_a = LinearRegression()\n",
    "model_a.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       -0.129470\n",
       "ZN          0.037960\n",
       "INDUS       0.060978\n",
       "CHAS        3.213498\n",
       "NOX       -16.499614\n",
       "RM          3.911519\n",
       "AGE        -0.012602\n",
       "DIS        -1.427742\n",
       "RAD         0.239546\n",
       "TAX        -0.008180\n",
       "PTRATIO    -0.935991\n",
       "B           0.011948\n",
       "LSTAT      -0.546562\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_a.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 21.615\n",
      "       Relative error: 16.55757%\n",
      "R-squared coefficient: 0.71265\n"
     ]
    }
   ],
   "source": [
    "model_b = Ridge(alpha=10)\n",
    "model_b.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.120803\n",
       "ZN         0.041276\n",
       "INDUS     -0.003992\n",
       "CHAS       2.143922\n",
       "NOX       -1.462094\n",
       "RM         3.632845\n",
       "AGE       -0.022260\n",
       "DIS       -1.207228\n",
       "RAD        0.220856\n",
       "TAX       -0.010126\n",
       "PTRATIO   -0.784938\n",
       "B          0.012374\n",
       "LSTAT     -0.606337\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_b.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 20.595\n",
      "       Relative error: 16.20789%\n",
      "R-squared coefficient: 0.72621\n"
     ]
    }
   ],
   "source": [
    "model_c = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "model_c.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.995690\n",
       "ZN         0.872971\n",
       "INDUS      0.424808\n",
       "CHAS       0.857462\n",
       "NOX       -1.943856\n",
       "RM         2.820988\n",
       "AGE       -0.351939\n",
       "DIS       -3.063072\n",
       "RAD        2.069621\n",
       "TAX       -1.356887\n",
       "PTRATIO   -2.098051\n",
       "B          1.060004\n",
       "LSTAT     -3.926623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_c.named_steps[\"lr\"].coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.129470</td>\n",
       "      <td>-0.120803</td>\n",
       "      <td>-0.995690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>0.037960</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.872971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.060978</td>\n",
       "      <td>-0.003992</td>\n",
       "      <td>0.424808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>3.213498</td>\n",
       "      <td>2.143922</td>\n",
       "      <td>0.857462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>-16.499614</td>\n",
       "      <td>-1.462094</td>\n",
       "      <td>-1.943856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>3.911519</td>\n",
       "      <td>3.632845</td>\n",
       "      <td>2.820988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.012602</td>\n",
       "      <td>-0.022260</td>\n",
       "      <td>-0.351939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.427742</td>\n",
       "      <td>-1.207228</td>\n",
       "      <td>-3.063072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>0.239546</td>\n",
       "      <td>0.220856</td>\n",
       "      <td>2.069621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.008180</td>\n",
       "      <td>-0.010126</td>\n",
       "      <td>-1.356887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.935991</td>\n",
       "      <td>-0.784938</td>\n",
       "      <td>-2.098051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>1.060004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.546562</td>\n",
       "      <td>-0.606337</td>\n",
       "      <td>-3.926623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear     ridge    scaled\n",
       "CRIM     -0.129470 -0.120803 -0.995690\n",
       "ZN        0.037960  0.041276  0.872971\n",
       "INDUS     0.060978 -0.003992  0.424808\n",
       "CHAS      3.213498  2.143922  0.857462\n",
       "NOX     -16.499614 -1.462094 -1.943856\n",
       "RM        3.911519  3.632845  2.820988\n",
       "AGE      -0.012602 -0.022260 -0.351939\n",
       "DIS      -1.427742 -1.207228 -3.063072\n",
       "RAD       0.239546  0.220856  2.069621\n",
       "TAX      -0.008180 -0.010126 -1.356887\n",
       "PTRATIO  -0.935991 -0.784938 -2.098051\n",
       "B         0.011948  0.012374  1.060004\n",
       "LSTAT    -0.546562 -0.606337 -3.926623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"linear\": model_a.coef_,\n",
    "    \"ridge\": model_b.coef_,\n",
    "    \"scaled\": model_c.named_steps[\"lr\"].coef_\n",
    "}, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In tutti e tre i modelli, dai segni dei coefficienti possiamo vedere quali fenomeni influiscono positivamente e negativamente sul prezzo\n",
    "  - ad es. il prezzo delle case è più alto se vicine al fiume (`CHAS`), mentre decresce con la criminalità (`CRIM`)\n",
    "- Nella regressione ridge i valori assoluti più alti sono ridotti (es. `NOX` e `RM`)\n",
    "- Con la standardizzazione delle feature otteniamo valori su scale simili, che possiamo confrontare alla pari\n",
    "  - ad es. negli altri modelli il coefficiente di `NOX` è alto perché i valori di tale variabile sono bassi (la media è circa 0.55, contro quelle superiori a 3 delle altre variabili)\n",
    "  - nel modello con standardizzazione assumono invece più peso il numero di stanza (`RM`) e la distanza dagli uffici di collocamento (`DIS`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione Lasso\n",
    "\n",
    "- La regolarizzazione L2 impedisce che i parametri del modello assumano valori troppo alti\n",
    "- I valori dei parametri sono comunque tutti non nulli, tutte le variabili vengono coinvolte nella predizione\n",
    "- Vorremmo addestrare un modello meno complesso, dove alcuni parametri hanno valori nulli, **ignorando completamente le variabili meno rilevanti**\n",
    "  - ad es. variabili con valori dipendenti da altre (_multicollinearità_)\n",
    "- Questo si può ottenere tramite la regolarizzazione L1, basata sulla norma 1, definita su un vettore $\\mathbf{x}$ di $n$ elementi come\n",
    "$$ \\left\\Vert\\mathbf{x}\\right\\Vert_1 = \\sum_{i=1}^n{\\left\\vert x_i\\right\\vert} = \\left\\vert x_1\\right\\vert+\\ldots+\\left\\vert x_n\\right\\vert $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La regressione _lasso_ consiste nella regressione lineare con regolarizzazione L1, basata quindi sul minimizzare la funzione d'errore\n",
    "$$ E = \\frac{1}{2m}\\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 + \\alpha\\left\\Vert\\mathbf{\\theta}\\right\\Vert_1 $$\n",
    "- Come per la regressione ridge, il parametro $\\alpha$ controlla il peso della regolarizzazione\n",
    "- La regressione lasso si esegue usando un modello `Lasso`, su cui possiamo impostare come in `Ridge` il parametro `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('regr',\n",
       "                 Lasso(alpha=2, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "                       normalize=False, positive=False, precompute=False,\n",
       "                       random_state=None, selection='cyclic', tol=0.0001,\n",
       "                       warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=2))\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vediamo i coefficienti del modello risultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.000000\n",
       "ZN         0.000000\n",
       "INDUS     -0.000000\n",
       "CHAS       0.000000\n",
       "NOX       -0.000000\n",
       "RM         2.137434\n",
       "AGE       -0.000000\n",
       "DIS        0.000000\n",
       "RAD       -0.000000\n",
       "TAX       -0.000000\n",
       "PTRATIO   -0.571281\n",
       "B          0.000000\n",
       "LSTAT     -3.490547\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La regolarizzazione L1 ha contribuito ad annullare quanti più coefficienti possibile, creando un modello che considera solo 3 variabili\n",
    "- Ma qual'è l'accuratezza di tale modello?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 30.795\n",
      "       Relative error: 22.08914%\n",
      "R-squared coefficient: 0.59062\n"
     ]
    }
   ],
   "source": [
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza è nettamente peggiore rispetto ai casi precedenti\n",
    "- In questo caso la regolarizzazione è stata quindi eccessiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede diminuendo il parametro `alpha`, ovvero il peso della regolarizzazione?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('regr',\n",
       "                 Lasso(alpha=0.2, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=1000, normalize=False, positive=False,\n",
       "                       precompute=False, random_state=None, selection='cyclic',\n",
       "                       tol=0.0001, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=0.2)) # <-- cambiato da 2\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.394705\n",
       "ZN         0.192948\n",
       "INDUS     -0.000000\n",
       "CHAS       0.827011\n",
       "NOX       -0.812358\n",
       "RM         2.944153\n",
       "AGE       -0.000000\n",
       "DIS       -1.514910\n",
       "RAD        0.000000\n",
       "TAX       -0.000000\n",
       "PTRATIO   -1.698942\n",
       "B          0.842742\n",
       "LSTAT     -4.009724\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I coefficienti non nulli sono aumentati da 5 a 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 22.527\n",
      "       Relative error: 16.62391%\n",
      "R-squared coefficient: 0.70053\n"
     ]
    }
   ],
   "source": [
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza è di poco inferiore a quella ottenuta con gli altri modelli\n",
    "- Questo modello richiede però solo 9 variabili invece di 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Elastic Net\n",
    "\n",
    "- La regressione _elastic net_ combina insieme le regolarizzazioni L2 e L1 usate in ridge e lasso\n",
    "- Si applica in scikit-learn tramite la classe `ElasticNet`, per cui l'errore è calcolato come:\n",
    "$$ E = \\underbrace{\\frac{1}{2m} ||X\\theta - y||_2 ^ 2}_{\\text{errore sui dati}} + \\underbrace{\\alpha \\rho ||\\theta||_1}_{\\text{L1}} + \\underbrace{\\frac{\\alpha(1-\\rho)}{2} ||\\theta||_2 ^ 2}_{\\text{L2}} $$\n",
    "- I parametri impostabili sono\n",
    "  - `alpha` ($\\alpha$) che determina il peso generale della regolarizzazione\n",
    "  - `l1_ratio` ($\\rho$, compreso tra 0 e 1) che determina il peso di L1 relativo al totale (con $\\rho=1$ si ha la regressione lasso, con $\\rho=0$ la ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 22.092\n",
      "       Relative error: 16.18298%\n",
      "R-squared coefficient: 0.70631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"regr\", ElasticNet(alpha=0.2, l1_ratio=0.1))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 2: Elastic net con pesi separati\n",
    "\n",
    "- **(2a)** Definire una funzione `elastic_net_with_alphas` che restituisca un modello elastic net (non addestrato) con pesi dati separatamente per la regolarizzazione L2 e L1\n",
    "  - si ricordi che il parametro `alpha` è la somma dei due pesi\n",
    "- **(2b)** Servendosi di tale funzione, addestrare e validare un modello elastic net con $\\alpha_{L2}=1, \\alpha_{L1}=0.1$ e standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_with_alphas(alpha_l2, alpha_l1):\n",
    "    alpha = alpha_l1 + alpha_l2\n",
    "    l1_ratio = alpha_l1 / alpha\n",
    "    return ElasticNet(alpha=alpha, l1_ratio=l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 28.122\n",
      "       Relative error: 18.96992%\n",
      "R-squared coefficient: 0.62615\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  elastic_net_with_alphas(1, 0.1))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ripasso: Regressione polinomiale univariata\n",
    "\n",
    "- Abbiamo visto in precedenza la regressione polinomiale su una sola variabile $X$ (univariata), corrispondente alla regressione lineare sulle variabili $X,X^2,X^3,\\ldots$\n",
    "- Per generare queste variabili utilizziamo il filtro `PolynomialFeatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Siano date ad esempio due osservazioni di una variabile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([ [ 2],\n",
    "                    [-3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo ottenere ad es. le potenze fino al 4° grado\n",
    "  - `include_bias=True` specifica di non includere il termine di grado 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   4.,   8.,  16.],\n",
       "       [ -3.,   9., -27.,  81.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         X   X^2   X^3   X^4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione polinomiale multivariata\n",
    "\n",
    "- In presenza di più di una variabile, la regressione polinomiale genera tutti i possibili termini fino al grado impostato, includendo anche **termini basati su più variabili**\n",
    "- Vediamo un esempio con 2 generiche variabili $A$ e $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     A   B\n",
    "sample = np.array([ [ 2, -3],\n",
    "                    [ 4, -5] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applicando il filtro `PolynomialFeatures` con grado 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,  -3.,   4.,  -6.,   9.],\n",
       "       [  4.,  -5.,  16., -20.,  25.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         A     B    A^2   A*B   B^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le variabili generate (escludendo il grado nullo) sono 5: $A,B,A^2,AB,B^2$\n",
    "- Oltre ai quadrati delle singole variabili abbiamo quindi anche i prodotti tra di esse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo usare il metodo `get_feature_names` del filtro per avere una lista delle variabili calcolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0', 'x1', 'x0^2', 'x0 x1', 'x1^2']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Di default le variabili sono chiamate `x0`, `x1`, ...\n",
    "- È però possibile specificare i nomi alle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'A^2', 'A B', 'B^2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando il grado massimo, le variabili generate **aumentano rapidamente**\n",
    "- Ad esempio, aumentando il grado da 2 a 3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2.,   -3.,    4.,   -6.,    9.,    8.,  -12.,   18.,  -27.],\n",
       "       [   4.,   -5.,   16.,  -20.,   25.,   64.,  -80.,  100., -125.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...generiamo 9 variabili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'A^2', 'A B', 'B^2', 'A^3', 'A^2 B', 'A B^2', 'B^3']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede con un numero iniziale di variabili più alto?\n",
    "- Prendiamo ad esempio la matrice `X_train`, con 13 variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 13)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generando le feature polinomiali con grado massimo 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 104)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...otteniamo 104 feature distinte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Le feature includono infatti tutte le possibili coppie di variabili, oltre ai quadrati di ciascuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TAX^2',\n",
       " 'TAX PTRATIO',\n",
       " 'TAX B',\n",
       " 'TAX LSTAT',\n",
       " 'PTRATIO^2',\n",
       " 'PTRATIO B',\n",
       " 'PTRATIO LSTAT',\n",
       " 'B^2',\n",
       " 'B LSTAT',\n",
       " 'LSTAT^2']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names(X.columns)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando ulteriormente il grado, il numero di variabili cresce enormemente\n",
    "  - con grado 10 si supera il milione di variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 559)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 2379)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 8567)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "poly.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 27131)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=6, include_bias=False)\n",
    "poly.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- All'aumentare delle variabili, aumenta il tempo necessario per l'addestramento del modello\n",
    "- Proviamo ad esempio ad addestrare un modello ElasticNet polinomiale di grado 2, standardizzando le feature generate\n",
    "- Usiamo il comando \"magico\" `%time` per riportare in output il tempo di esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 4 ms, total: 16 ms\n",
      "Wall time: 7.99 ms\n",
      "   Mean squared error: 19.854\n",
      "       Relative error: 15.44921%\n",
      "R-squared coefficient: 0.73606\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"regr\",   ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'addestramento richiede una frazione di secondo, anche per via del numero limitato di istanze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Verifichiamo ora cosa accade con grado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 s, sys: 324 ms, total: 1.88 s\n",
      "Wall time: 1.55 s\n",
      "   Mean squared error: 11.969\n",
      "       Relative error: 11.63031%\n",
      "R-squared coefficient: 0.84089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170.67231189879794, tolerance: 2.9769638753709198\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=5, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"regr\",   ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza del modello è migliorata sensibilmente, ma **il tempo per addestrarlo è aumentato di oltre 100 volte**\n",
    "  - con dataset più grandi, avremmo tempi di addestramento insostenibili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 3: Feature polinomiali e standardizzazione\n",
    "\n",
    "- **(3a)** Addestrare e validare un modello elastic net `(alpha=0.5, l1_ratio=0.2)` su feature polinomiali di 3° grado, applicando la standardizzazione alle feature originali invece che a quelle generate dal filtro `PolynomialFeatures`\n",
    "- **(3b)** Addestrare e validare un modello elastic net come sopra, applicando la standardizzazione sia alle feature originali che a quelle polinomiali generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 14.398\n",
      "       Relative error: 12.98614%\n",
      "R-squared coefficient: 0.80859\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"poly\",   PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"regr\",   ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 15.09\n",
      "       Relative error: 13.08361%\n",
      "R-squared coefficient: 0.7994\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"poly\",   PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"scale2\", StandardScaler()),\n",
    "    (\"regr\",   ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione con Funzioni Kernel\n",
    "\n",
    "- Nella regressione polinomiale si eseguono prodotti tra dati con dimensioni aggiunte e rappresentate esplicitamente\n",
    "- Le _funzioni kernel_ permettono di calcolare gli stessi prodotti senza calcolare esplicitamente le dimensioni aggiunte\n",
    "- Questo permette di ottenere modelli non lineari senza l'aggiunta di variabili\n",
    "- Esistono diverse funzioni kernel utilizzabili con diversi parametri impostabili\n",
    "- Ad esempio, il kernel polinomiale è definito dalla formula\n",
    "$$ K(\\mathbf{a},\\mathbf{b}) = \\left(\\mathbf{a}\\cdot\\mathbf{b}+c\\right)^d $$\n",
    "  - $d$ e $c$ sono parametri del kernel, in particolare $d$ è il grado del polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La classe `KernelRidge` implementa la regressione ridge con l'applicazione di una funzione kernel\n",
    "- Col parametro `kernel` si indica il tipo di kernel con una stringa, ad es. `\"poly\"` per un kernel polinomiale\n",
    "- Ulteriori parametri riguardano il kernel, per quello polinomiale sono `degree` ($d$) e `coef0` ($c$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 36 ms, total: 60 ms\n",
      "Wall time: 22.2 ms\n",
      "   Mean squared error: 14.765\n",
      "       Relative error: 13.09973%\n",
      "R-squared coefficient: 0.80371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Abbiamo ottenuto un'accuratezza più elevata rispetto ai modelli lineari, ma in tempi molto più brevi rispetto alla regressione polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando arbitrariamente il grado del polinomio, il tempo impiegato per l'addestramento non cambia\n",
    "  - in questo caso comunque un grado alto non porta ad un modello accurato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 28 ms, total: 56 ms\n",
      "Wall time: 17.4 ms\n",
      "   Mean squared error: 1.9649e+09\n",
      "       Relative error: 81646.89281%\n",
      "R-squared coefficient: -2.6122e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/ridge.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=8.55393e-21): result may not be accurate.\n",
      "  overwrite_a=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=20))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Va però ricordato che la complessità cresce quadraticamente col numero di istanze di training\n",
    "- Ad esempio, addestrando un modello su _tutti_ i dati invece che sul solo training set, quindi sul 50\\% di istanze in più..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 ms, sys: 52 ms, total: 92 ms\n",
      "Wall time: 30.2 ms\n",
      "   Mean squared error: 8.2617\n",
      "       Relative error: 8.99352%\n",
      "R-squared coefficient: 0.89017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X, y)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ... il tempo necessario è circa il doppio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo testare anche funzioni kernel diverse, ad esempio RBF (_radial basis function_)\n",
    "  - RBF ha valori tanto più elevati quanto più i valori X sono vicini a 0 (ovvero la media, usando dati standardizzati)\n",
    "- La funzione RBF ha la forma di una gaussiana, di cui si può impostare l'ampiezza col parametro `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 8 ms, total: 20 ms\n",
      "Wall time: 6.87 ms\n",
      "   Mean squared error: 43.906\n",
      "       Relative error: 19.38425%\n",
      "R-squared coefficient: 0.41632\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"rbf\", gamma=0.01))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In questo caso specifico il kernel RBF non funziona bene tanto quanto il polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 4: Ripasso cross validation\n",
    "\n",
    "- **(4a)** Definire un modello di regressione kernel ridge su feature standardizzate con kernel polinomiale di 3° grado e $\\alpha=10$\n",
    "- **(4b)** Eseguire la cross-validation del modello, utilizzando 5 fold dell'intero set di dati (`X` e `y`) generati dall'oggetto `kf` definito sotto\n",
    "- **(4c)** Calcolare la media e la deviazione standard dei punteggi R² ottenuti dalla validazione di ciascun fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessari\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "# generatore di fold casuali da usare\n",
    "kf = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=10, kernel=\"poly\", degree=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X, y, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8382685697714585, 0.050923469784573724)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cv_results[\"test_score\"]\n",
    "cv_scores.mean(), cv_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ricerca degli iperparametri con grid search\n",
    "\n",
    "- Sui modelli utilizzati finora abbiamo impostato manualmente i valori di diversi iperparametri\n",
    "  - grado della regressione polinomiale, peso della regolarizzazione, ...\n",
    "- L'accuratezza del modello può dipendere fortemente da questi valori\n",
    "- Scelto un generico modello da utilizzare (es. regressione polinomiale o kernel ridge), vorremmo **individuare i valori degli iperparametri che ne massimizzino l'accuratezza**\n",
    "- scikit-learn fornisce un supporto per eseguire automaticamente la cross validation di un modello con diversi valori degli iperparametri tramite la _grid search_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Consideriamo ad esempio un modello _elastic net_ di cui fissiamo arbitrariamente il parametro `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(l1_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vorremmo trovare il migliore valore possibile del parametro `alpha` tra un insieme di valori possibili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_alphas = [0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creiamo ora la _griglia_ dei parametri, ovvero un dizionario in cui associamo ai nomi dei parametri variabili i valori che possono assumere\n",
    "- In questo caso abbiamo un unico parametro variabile, `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"alpha\": candidate_alphas}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Definiamo ora un modello `GridSearchCV` indicando\n",
    "  - il modello \"base\" con i parametri fissati a priori\n",
    "  - la griglia dei parametri variabili\n",
    "  - un metodo `cv` di cross validation da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(model, grid, cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Come per i modelli base, usiamo il metodo `fit` per eseguire l'addestramento, passando la matrice X e il vettore y\n",
    "- Per ogni valore possibile di `alpha`, scikit-learn esegue la cross-validation per calcolare il punteggio R² medio del modello con quel valore di `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In seguito ai test, il modello impostato viene (di default) riaddestrato su tutti i dati forniti, usando gli iperparametri che han dato il miglior punteggio medio\n",
    "- Il modello finale è accessibile all'attributo `gs_best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.2,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dall'attributo `best_params_` possiamo vedere quali sono i valori selezionati dalla griglia degli iperparametri per tale modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'oggetto `GridSearchCV` addestrato può essere usato come un normale modello di predizione, le chiamate a `predict` e altri metodi sono girate al `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.35759953])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prezzo predetto per la prima riga del validation set\n",
    "gs.predict(X_val.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.35759953])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalente a\n",
    "gs.best_estimator_.predict(X_val.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo valutare il modello sul validation set \"esterno\", non utilizzato nella grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 21.905\n",
      "       Relative error: 16.80121%\n",
      "R-squared coefficient: 0.7088\n"
     ]
    }
   ],
   "source": [
    "print_eval(X_val, y_val, gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'attributo `cv_results_` fornisce risultati dettagliati su tutti gli iperparametri testati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00298381, 0.00214591, 0.00212278]),\n",
       " 'std_fit_time': array([0.00125824, 0.00039233, 0.0005205 ]),\n",
       " 'mean_score_time': array([0.0047997 , 0.00126004, 0.0009779 ]),\n",
       " 'std_score_time': array([4.35237515e-03, 4.04896973e-04, 6.35746796e-05]),\n",
       " 'param_alpha': masked_array(data=[0.1, 1, 10],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}],\n",
       " 'split0_test_score': array([0.72725222, 0.71402229, 0.62476928]),\n",
       " 'split1_test_score': array([0.49684999, 0.52396629, 0.37364136]),\n",
       " 'split2_test_score': array([0.63715729, 0.59460273, 0.57229431]),\n",
       " 'split3_test_score': array([0.72120542, 0.67019429, 0.53969277]),\n",
       " 'split4_test_score': array([0.80022849, 0.7617415 , 0.62314866]),\n",
       " 'mean_test_score': array([0.67615597, 0.65270417, 0.54642735]),\n",
       " 'std_test_score': array([0.1038295 , 0.0848443 , 0.09260055]),\n",
       " 'rank_test_score': array([1, 2, 3], dtype=int32)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Incapsuliamo tali risultati in un DataFrame per visualizzarli meglio ed ordinarli per punteggio decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.727252</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.637157</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.800228</td>\n",
       "      <td>0.676156</td>\n",
       "      <td>0.103829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.523966</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>0.670194</td>\n",
       "      <td>0.761741</td>\n",
       "      <td>0.652704</td>\n",
       "      <td>0.084844</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.624769</td>\n",
       "      <td>0.373641</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.623149</td>\n",
       "      <td>0.546427</td>\n",
       "      <td>0.092601</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.002984      0.001258         0.004800        0.004352         0.1   \n",
       "1       0.002146      0.000392         0.001260        0.000405           1   \n",
       "2       0.002123      0.000520         0.000978        0.000064          10   \n",
       "\n",
       "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.1}           0.727252           0.496850           0.637157   \n",
       "1    {'alpha': 1}           0.714022           0.523966           0.594603   \n",
       "2   {'alpha': 10}           0.624769           0.373641           0.572294   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.721205           0.800228         0.676156        0.103829   \n",
       "1           0.670194           0.761741         0.652704        0.084844   \n",
       "2           0.539693           0.623149         0.546427        0.092601   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(gs.cv_results_)\n",
    "results.sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati riportati per ciascun test includono:\n",
    "- `{mean|std}_{fit|score}_time`: media/dev. standard dei tempi di addestramento/valutazione sui diversi fold\n",
    "- `param_X`: valore del parametro X\n",
    "- `params`: dizionario col valore di tutti i parametri\n",
    "- `splitN_test_score`: punteggio della valutazione sull'N-esimo fold\n",
    "- `{mean|std}_test_score`: media/dev. standard dei punteggi sui diversi fold\n",
    "- `rank_test_score`: ranking del punteggio, 1 è il migliore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede con due iperparametri variabili?\n",
    "- Oltre a 3 valori possibili per `alpha`, impostiamo 3 valori possibili anche per `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "grid = {\n",
    "    \"alpha\":    [0.1, 1, 10],\n",
    "    \"l1_ratio\": [0.1, 0.2, 0.3]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.727791</td>\n",
       "      <td>0.499753</td>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.721171</td>\n",
       "      <td>0.800223</td>\n",
       "      <td>0.676763</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.2}</td>\n",
       "      <td>0.727252</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.637157</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.800228</td>\n",
       "      <td>0.676156</td>\n",
       "      <td>0.103829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.726624</td>\n",
       "      <td>0.493642</td>\n",
       "      <td>0.637503</td>\n",
       "      <td>0.721081</td>\n",
       "      <td>0.800186</td>\n",
       "      <td>0.675417</td>\n",
       "      <td>0.104841</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.714960</td>\n",
       "      <td>0.526437</td>\n",
       "      <td>0.595148</td>\n",
       "      <td>0.670794</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.653954</td>\n",
       "      <td>0.084608</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.2}</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.523966</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>0.670194</td>\n",
       "      <td>0.761741</td>\n",
       "      <td>0.652704</td>\n",
       "      <td>0.084844</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>0.521933</td>\n",
       "      <td>0.594699</td>\n",
       "      <td>0.669538</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.651835</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.638007</td>\n",
       "      <td>0.397883</td>\n",
       "      <td>0.577252</td>\n",
       "      <td>0.557198</td>\n",
       "      <td>0.655982</td>\n",
       "      <td>0.564984</td>\n",
       "      <td>0.091643</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.2}</td>\n",
       "      <td>0.624769</td>\n",
       "      <td>0.373641</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.623149</td>\n",
       "      <td>0.546427</td>\n",
       "      <td>0.092601</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.614417</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.570172</td>\n",
       "      <td>0.529856</td>\n",
       "      <td>0.607627</td>\n",
       "      <td>0.535700</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.001963      0.000190         0.000972        0.000066         0.1   \n",
       "1       0.002242      0.000505         0.001216        0.000466         0.1   \n",
       "2       0.001895      0.000071         0.000961        0.000033         0.1   \n",
       "3       0.002140      0.000397         0.001241        0.000467           1   \n",
       "4       0.001805      0.000213         0.000927        0.000054           1   \n",
       "5       0.002306      0.000715         0.000929        0.000029           1   \n",
       "6       0.001713      0.000094         0.000927        0.000036          10   \n",
       "7       0.001912      0.000495         0.000892        0.000030          10   \n",
       "8       0.001642      0.000086         0.000878        0.000031          10   \n",
       "\n",
       "  param_l1_ratio                           params  split0_test_score  \\\n",
       "0            0.1  {'alpha': 0.1, 'l1_ratio': 0.1}           0.727791   \n",
       "1            0.2  {'alpha': 0.1, 'l1_ratio': 0.2}           0.727252   \n",
       "2            0.3  {'alpha': 0.1, 'l1_ratio': 0.3}           0.726624   \n",
       "3            0.1    {'alpha': 1, 'l1_ratio': 0.1}           0.714960   \n",
       "4            0.2    {'alpha': 1, 'l1_ratio': 0.2}           0.714022   \n",
       "5            0.3    {'alpha': 1, 'l1_ratio': 0.3}           0.714237   \n",
       "6            0.1   {'alpha': 10, 'l1_ratio': 0.1}           0.638007   \n",
       "7            0.2   {'alpha': 10, 'l1_ratio': 0.2}           0.624769   \n",
       "8            0.3   {'alpha': 10, 'l1_ratio': 0.3}           0.614417   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.499753           0.636757           0.721171           0.800223   \n",
       "1           0.496850           0.637157           0.721205           0.800228   \n",
       "2           0.493642           0.637503           0.721081           0.800186   \n",
       "3           0.526437           0.595148           0.670794           0.763423   \n",
       "4           0.523966           0.594603           0.670194           0.761741   \n",
       "5           0.521933           0.594699           0.669538           0.759777   \n",
       "6           0.397883           0.577252           0.557198           0.655982   \n",
       "7           0.373641           0.572294           0.539693           0.623149   \n",
       "8           0.357906           0.570172           0.529856           0.607627   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.676763        0.102900                1  \n",
       "1         0.676156        0.103829                2  \n",
       "2         0.675417        0.104841                3  \n",
       "3         0.653954        0.084608                4  \n",
       "4         0.652704        0.084844                5  \n",
       "5         0.651835        0.084962                6  \n",
       "6         0.564984        0.091643                7  \n",
       "7         0.546427        0.092601                8  \n",
       "8         0.535700        0.094342                9  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn ha generato e testato **tutte le combinazioni possibili** dei valori degli iperparametri, in tutto 3×3 = 9 configurazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid search su pipeline\n",
    "\n",
    "- Possiamo usare `GridSearchCV` anche con una pipeline, testando diversi valori anche per i parametri dei filtri\n",
    "- Consideriamo ad esempio un modello polinomiale con regolarizzazione L2, su cui sono variabili\n",
    "  - il grado del polinomio (attributo `degree` del filtro `poly`)\n",
    "  - il peso della regolarizzazione (attributo `alpha` del modello `regr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\",  PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per riferirsi ai parametri dei singoli componenti, usiamo la notazione `componente__parametro` _(con DUE underscore in mezzo)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"poly__degree\": [2, 3],      # <- grado polinomio\n",
    "    \"regr__alpha\":  [0.1, 1, 10] # <- regolarizzazione\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_poly__degree</th>\n",
       "      <th>param_regr__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'poly__degree': 2, 'regr__alpha': 1}</td>\n",
       "      <td>0.835447</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.802240</td>\n",
       "      <td>0.810611</td>\n",
       "      <td>0.882463</td>\n",
       "      <td>0.785038</td>\n",
       "      <td>0.098802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'poly__degree': 2, 'regr__alpha': 10}</td>\n",
       "      <td>0.842239</td>\n",
       "      <td>0.594859</td>\n",
       "      <td>0.750900</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>0.856246</td>\n",
       "      <td>0.767713</td>\n",
       "      <td>0.094450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'poly__degree': 2, 'regr__alpha': 0.1}</td>\n",
       "      <td>0.824409</td>\n",
       "      <td>0.648065</td>\n",
       "      <td>0.850516</td>\n",
       "      <td>0.816894</td>\n",
       "      <td>0.493138</td>\n",
       "      <td>0.726662</td>\n",
       "      <td>0.136693</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'poly__degree': 3, 'regr__alpha': 10}</td>\n",
       "      <td>0.853895</td>\n",
       "      <td>0.454814</td>\n",
       "      <td>0.773790</td>\n",
       "      <td>0.748621</td>\n",
       "      <td>0.333358</td>\n",
       "      <td>0.633023</td>\n",
       "      <td>0.201746</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'poly__degree': 3, 'regr__alpha': 1}</td>\n",
       "      <td>0.852441</td>\n",
       "      <td>0.568150</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.775824</td>\n",
       "      <td>-3.047350</td>\n",
       "      <td>-0.006925</td>\n",
       "      <td>1.517645</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'poly__degree': 3, 'regr__alpha': 0.1}</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.648950</td>\n",
       "      <td>0.784034</td>\n",
       "      <td>-3.348237</td>\n",
       "      <td>-0.107007</td>\n",
       "      <td>1.615276</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       0.012698      0.002000         0.002977        0.000900   \n",
       "2       0.015762      0.003819         0.002716        0.000884   \n",
       "0       0.014436      0.005432         0.002357        0.000504   \n",
       "5       0.027469      0.012958         0.015329        0.009409   \n",
       "4       0.025623      0.002924         0.009970        0.001819   \n",
       "3       0.025479      0.001802         0.011557        0.001309   \n",
       "\n",
       "  param_poly__degree param_regr__alpha  \\\n",
       "1                  2                 1   \n",
       "2                  2                10   \n",
       "0                  2               0.1   \n",
       "5                  3                10   \n",
       "4                  3                 1   \n",
       "3                  3               0.1   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "1    {'poly__degree': 2, 'regr__alpha': 1}           0.835447   \n",
       "2   {'poly__degree': 2, 'regr__alpha': 10}           0.842239   \n",
       "0  {'poly__degree': 2, 'regr__alpha': 0.1}           0.824409   \n",
       "5   {'poly__degree': 3, 'regr__alpha': 10}           0.853895   \n",
       "4    {'poly__degree': 3, 'regr__alpha': 1}           0.852441   \n",
       "3  {'poly__degree': 3, 'regr__alpha': 0.1}           0.692042   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.596491           0.802240           0.810611           0.882463   \n",
       "2           0.594859           0.750900           0.795789           0.856246   \n",
       "0           0.648065           0.850516           0.816894           0.493138   \n",
       "5           0.454814           0.773790           0.748621           0.333358   \n",
       "4           0.568150           0.794898           0.775824          -3.047350   \n",
       "3           0.664729           0.648950           0.784034          -3.348237   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.785038        0.098802                1  \n",
       "2         0.767713        0.094450                2  \n",
       "0         0.726662        0.136693                3  \n",
       "5         0.633023        0.201746                4  \n",
       "4        -0.006925        1.517645                5  \n",
       "3        -0.107007        1.615276                6  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Nella pipeline possiamo impostare un intero componente come parametro variabile, con la possibilità di rimuoverlo impostandolo a `None`\n",
    "- Possiamo ad esempio testare un modello con e senza standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", None),\n",
    "    (\"regr\",  Ridge())\n",
    "])\n",
    "grid = {\n",
    "    # scale = standardizzazione oppure nulla\n",
    "    \"scale\": [None, StandardScaler()],\n",
    "    \"regr__alpha\": [0.1, 1, 10]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regr__alpha</th>\n",
       "      <th>param_scale</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'regr__alpha': 1, 'scale': StandardScaler(cop...</td>\n",
       "      <td>0.735767</td>\n",
       "      <td>0.495302</td>\n",
       "      <td>0.657167</td>\n",
       "      <td>0.720101</td>\n",
       "      <td>0.800925</td>\n",
       "      <td>0.681459</td>\n",
       "      <td>0.104112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.1</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'regr__alpha': 0.1, 'scale': StandardScaler(c...</td>\n",
       "      <td>0.735121</td>\n",
       "      <td>0.495993</td>\n",
       "      <td>0.656523</td>\n",
       "      <td>0.720110</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.681383</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>10</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>{'regr__alpha': 10, 'scale': StandardScaler(co...</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.487396</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.718528</td>\n",
       "      <td>0.798668</td>\n",
       "      <td>0.681269</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'regr__alpha': 0.1, 'scale': None}</td>\n",
       "      <td>0.734675</td>\n",
       "      <td>0.494498</td>\n",
       "      <td>0.655446</td>\n",
       "      <td>0.718577</td>\n",
       "      <td>0.801852</td>\n",
       "      <td>0.680615</td>\n",
       "      <td>0.104470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'regr__alpha': 1, 'scale': None}</td>\n",
       "      <td>0.730686</td>\n",
       "      <td>0.487010</td>\n",
       "      <td>0.649269</td>\n",
       "      <td>0.712555</td>\n",
       "      <td>0.801934</td>\n",
       "      <td>0.675890</td>\n",
       "      <td>0.106636</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>{'regr__alpha': 10, 'scale': None}</td>\n",
       "      <td>0.726584</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.641675</td>\n",
       "      <td>0.719819</td>\n",
       "      <td>0.801424</td>\n",
       "      <td>0.675202</td>\n",
       "      <td>0.106541</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.002675      0.000134         0.001051        0.000047   \n",
       "1       0.006050      0.003837         0.001187        0.000148   \n",
       "5       0.002648      0.000130         0.001044        0.000030   \n",
       "0       0.004251      0.002839         0.001726        0.000932   \n",
       "2       0.001795      0.000049         0.000970        0.000084   \n",
       "4       0.001774      0.000103         0.000917        0.000024   \n",
       "\n",
       "  param_regr__alpha                                        param_scale  \\\n",
       "3                 1  StandardScaler(copy=True, with_mean=True, with...   \n",
       "1               0.1  StandardScaler(copy=True, with_mean=True, with...   \n",
       "5                10  StandardScaler(copy=True, with_mean=True, with...   \n",
       "0               0.1                                               None   \n",
       "2                 1                                               None   \n",
       "4                10                                               None   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'regr__alpha': 1, 'scale': StandardScaler(cop...           0.735767   \n",
       "1  {'regr__alpha': 0.1, 'scale': StandardScaler(c...           0.735121   \n",
       "5  {'regr__alpha': 10, 'scale': StandardScaler(co...           0.741449   \n",
       "0                {'regr__alpha': 0.1, 'scale': None}           0.734675   \n",
       "2                  {'regr__alpha': 1, 'scale': None}           0.730686   \n",
       "4                 {'regr__alpha': 10, 'scale': None}           0.726584   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.495302           0.657167           0.720101           0.800925   \n",
       "1           0.495993           0.656523           0.720110           0.801136   \n",
       "5           0.487396           0.662300           0.718528           0.798668   \n",
       "0           0.494498           0.655446           0.718577           0.801852   \n",
       "2           0.487010           0.649269           0.712555           0.801934   \n",
       "4           0.488528           0.641675           0.719819           0.801424   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.681459        0.104112                1  \n",
       "1         0.681383        0.103875                2  \n",
       "5         0.681269        0.106783                3  \n",
       "0         0.680615        0.104470                4  \n",
       "2         0.675890        0.106636                5  \n",
       "4         0.675202        0.106541                6  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 5: Grid search su regressione kernel ridge\n",
    "\n",
    "- **(5a)** Creare una funzione `grid_test` che, presi in input un modello e una griglia di parametri\n",
    "  - esegua una grid search con `X_train`, `y_train` come dati di addestramento con modello e parametri forniti, usando cross-validation a 5 fold\n",
    "  - stampi (`print(...)`) il dizionario con gli iperparametri selezionati del modello migliore\n",
    "  - stampi le misure di accuratezza (`print_eval`) sui dati `X_val`, `y_val`\n",
    "- **(5b)** Testare con la funzione sopra un modello di regressione elastic net polinomiale con\n",
    "  - grado 2 o 3\n",
    "  - standardizzazione delle feature generate\n",
    "  - `alpha` pari a 0.1, 1 o 10\n",
    "  - `l1_ratio` pari a 0.1, 0.25 o 0.5\n",
    "- **(5c)** Testare con la funzione sopra un modello kernel ridge con\n",
    "  - standardizzazione dei dati\n",
    "  - kernel polinomiale di grado compreso tra 2 e 10\n",
    "  - `alpha` (regolarizzazione) pari a 0.01, 0.1, 1 o 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_test(model, grid):\n",
    "    gs = GridSearchCV(model, grid, cv=kf)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(gs.best_params_)\n",
    "    print_eval(X_val, y_val, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 197.98020686962036, tolerance: 2.465989197026022\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.14783983447796, tolerance: 2.2563256431226772\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.80528399091236, tolerance: 2.406635866666666\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.99899354062654, tolerance: 2.2892318666666664\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 221.2608923594148, tolerance: 2.4742154074074074\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.21537987866759, tolerance: 2.465989197026022\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.869969625347949, tolerance: 2.2563256431226772\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.064804967557848, tolerance: 2.406635866666666\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.090362890005053, tolerance: 2.2892318666666664\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.17362330720789, tolerance: 2.4742154074074074\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.1220576296614126, tolerance: 2.465989197026022\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.29772868879536, tolerance: 2.4742154074074074\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1088.2700037814984, tolerance: 2.465989197026022\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 860.37985570618, tolerance: 2.2563256431226772\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 974.517671328996, tolerance: 2.406635866666666\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 890.498934696745, tolerance: 2.2892318666666664\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1051.1995217410376, tolerance: 2.4742154074074074\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 507.09856372432955, tolerance: 2.465989197026022\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 385.2009285608283, tolerance: 2.2563256431226772\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 521.6440445694019, tolerance: 2.406635866666666\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 364.84990944885226, tolerance: 2.2892318666666664\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 485.332385286742, tolerance: 2.4742154074074074\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 327.82019124265753, tolerance: 2.465989197026022\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.070328963232896, tolerance: 2.2563256431226772\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109.88251539776411, tolerance: 2.406635866666666\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 257.05132160675817, tolerance: 2.2892318666666664\n",
      "  positive)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 284.9476790830745, tolerance: 2.4742154074074074\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poly__degree': 2, 'regr__alpha': 0.1, 'regr__l1_ratio': 0.1}\n",
      "   Mean squared error: 15.041\n",
      "       Relative error: 13.87150%\n",
      "R-squared coefficient: 0.80004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 278.6543434185819, tolerance: 2.9769638753709198\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", ElasticNet())\n",
    "])\n",
    "grid = {\n",
    "    \"poly__degree\": [2, 3],\n",
    "    \"regr__alpha\": [0.1, 1, 10],\n",
    "    \"regr__l1_ratio\": [0.1, 0.25, 0.5]\n",
    "}\n",
    "grid_test(model, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regr__alpha': 1, 'regr__degree': 2}\n",
      "   Mean squared error: 11.303\n",
      "       Relative error: 12.20756%\n",
      "R-squared coefficient: 0.84973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", KernelRidge(kernel=\"poly\"))\n",
    "])\n",
    "grid = {\n",
    "    \"regr__degree\": range(2, 11),\n",
    "    \"regr__alpha\": [0.01, 0.1, 1, 10],\n",
    "}\n",
    "grid_test(model, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested cross-validation\n",
    "\n",
    "- Finora abbiamo validato il risultato finale della grid search su un validation set separato\n",
    "- La _nested cross-validation_ prevede che siano generati **k fold \"esterni\"** su tutti i dati disponibili e che **per ciascuno** si esegua il tuning degli iperparametri con una cross validation \"interna\" usando le parti di training dei fold esterni\n",
    "- I criteri con cui si eseguono le cross validation esterna ed interna possono differire, es. diverso numero di fold\n",
    "- Ipotizziamo ad esempio di usare 3 fold esterni e 5 interni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(3, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 6: Nested cross validation\n",
    "\n",
    "Implementare una funzione `nested_cv` che esegua la nested cross validation\n",
    "- predisporre una lista vuota in cui salvare i punteggi ottenuti su ogni fold esterno\n",
    "- usare un ciclo `for` per iterare tutti i fold esterni (T, V) del dataset `X`, `y`\n",
    "  - usare il metodo `split` di `outer_cv`, che fornisce per ogni fold gli indici delle istanze di training e di validation\n",
    "- su ciascun fold esterno, eseguire la grid search con modello e parametri dati in ingresso alla funzione sui dati T, applicando `inner_cv` come cross validation\n",
    "- per ogni modello generato, salvare nella lista di punteggi il R² ottenuto dalla validazione sui dati V\n",
    "- restituire la lista alla fine del ciclo\n",
    "- testare la funzione su uno dei modelli usati sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(model, grid):\n",
    "    results = []\n",
    "    for train_indices, val_indices in outer_cv.split(X, y):\n",
    "        gs = GridSearchCV(model, grid, cv=inner_cv)\n",
    "        gs.fit(X.iloc[train_indices], y.iloc[train_indices])\n",
    "        score = gs.score(X.iloc[val_indices], y.iloc[val_indices])\n",
    "        results.append(score)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/rrobby/.venvs/dia2020/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.857809313401843, 0.8443841766460665, 0.8875611674403587]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", KernelRidge(kernel=\"poly\"))\n",
    "])\n",
    "grid = {\n",
    "    \"regr__degree\": range(2, 11),\n",
    "    \"regr__alpha\": [0.01, 0.1, 1, 10],\n",
    "}\n",
    "nested_cv(model, grid)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
